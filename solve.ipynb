{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> In this workshop, we shall be creating an end-to-end application which can be used to recognize digits from images based on hardwritten digits dataset MNIST. \n",
    "    \n",
    "    - We shall create a simple neural network to recognize handwritten digits.\n",
    "    - We will test the model through own pictures.\n",
    "   \n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary modules and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "18e73f61d4e40d59db0c0b1ecea56dc22d18e013"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to handle input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "4bbbe1bb5e72e9458e05590cd7719ff15af363a7"
   },
   "outputs": [],
   "source": [
    "def loadImageFile(fileimage):\n",
    "    f = open(fileimage, \"rb\")\n",
    "\n",
    "    f.read(16)\n",
    "    pixels = 28*28\n",
    "    images_arr = []\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            img = []\n",
    "            for j in range(pixels):\n",
    "                pix = ord(f.read(1))\n",
    "                img.append(pix / 255)\n",
    "            images_arr.append(img)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    f.close()\n",
    "    image_sets = np.array(images_arr)\n",
    "    return image_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load Label Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c17196edfad2d9a8ce2f9be66e80496c209d18b7"
   },
   "outputs": [],
   "source": [
    "def loadLabelFile(filelabel):\n",
    "    f = open(filelabel, \"rb\")\n",
    "    f.read(8)\n",
    "\n",
    "    labels_arr = []\n",
    "\n",
    "    while True:\n",
    "        row = [0 for x in range(10)]\n",
    "        try:\n",
    "            label = ord(f.read(1))\n",
    "            row[label] = 1\n",
    "            labels_arr.append(row)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    f.close()\n",
    "    label_sets = np.array(labels_arr)\n",
    "    return label_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "09d093fb40e3d050a45ed7a582ed86f53fb97712"
   },
   "outputs": [],
   "source": [
    "train_images = loadImageFile(\"./data/train-images.idx3-ubyte\")\n",
    "train_labels = loadLabelFile(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b11530b8eb21880e3a1efe87ee5f895b1c63ac6c"
   },
   "outputs": [],
   "source": [
    "test_images = loadImageFile(\"...\")\n",
    "test_labels = loadLabelFile(\"./data/t10k-labels.idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the data to represent images as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "ec284103fd067fe6a284bf767f3d446ba5891242"
   },
   "outputs": [],
   "source": [
    "x_train = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "x_test = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Sequential Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "1461a5ae3b172ff0558cf4d529a1f3c1544e4093"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Convolutional Neuron Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "68d7d0522e3d08262c626e8ac40a90386a6735f1"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "8026bdf095bedcd7249edb1149ccf0005ae4d71c"
   },
   "outputs": [],
   "source": [
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Fully connected layer\n",
    "\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "31a30bb3b861477e9a19446bf31c69999f4aff94"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit your model with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "8d0b56afd339355b60540d180bc980dfdcd9cfa6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 102s - loss: 0.1501 - acc: 0.9539 - val_loss: 0.0436 - val_acc: 0.9865\n",
      "Epoch 2/10\n",
      " - 107s - loss: 0.0406 - acc: 0.9878 - val_loss: 0.0325 - val_acc: 0.9895\n",
      "Epoch 3/10\n",
      " - 117s - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0214 - val_acc: 0.9930\n",
      "Epoch 4/10\n",
      " - 116s - loss: 0.0210 - acc: 0.9932 - val_loss: 0.0281 - val_acc: 0.9904\n",
      "Epoch 5/10\n",
      " - 107s - loss: 0.0182 - acc: 0.9945 - val_loss: 0.0254 - val_acc: 0.9915\n",
      "Epoch 6/10\n",
      " - 130s - loss: 0.0142 - acc: 0.9954 - val_loss: 0.0330 - val_acc: 0.9913\n",
      "Epoch 7/10\n",
      " - 128s - loss: 0.0129 - acc: 0.9956 - val_loss: 0.0265 - val_acc: 0.9938\n",
      "Epoch 8/10\n",
      " - 122s - loss: 0.0127 - acc: 0.9958 - val_loss: 0.0285 - val_acc: 0.9924\n",
      "Epoch 9/10\n",
      " - 114s - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0242 - val_acc: 0.9933\n",
      "Epoch 10/10\n",
      " - 108s - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0228 - val_acc: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a9b4905f8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=100,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "15f1b5e992bdaa163c6764e92b33f9596640081a"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "3256139cde690795d5c60d340a79354360ca4032"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2615dbc51aeb523aec623e0253080ae3987793f3"
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xprilion/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/xprilion/intelpython3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "x = imread('./test/test_3.png', mode='L')\n",
    "\n",
    "x = imresize(x, (28, 28))\n",
    "\n",
    "x = x.reshape(1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "[3]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(x)\n",
    "print(out)\n",
    "print(np.argmax(out, axis=1))\n",
    "# convert the response to a string\n",
    "response = np.argmax(out, axis=1)\n",
    "print(str(response[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
